[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "fp_essentials.html#differences-across-groups",
    "href": "fp_essentials.html#differences-across-groups",
    "title": "Workshop3",
    "section": "Differences across groups",
    "text": "Differences across groups\n\nBinary\n\n\n\n  Year I  Year II Year III \n     327      277      221 \n\n\n\n  0   1 \n327 221 \n\n\n\n\n\n\nBivariate\nMultivariate\n Interaction\n\n\n\n\n(Intercept)\n−0.150*** (0.036)\n−0.142** (0.051)\n−0.184** (0.061)\n\n\nmoved\n0.234*** (0.045)\n0.273*** (0.055)\n0.334*** (0.073)\n\n\nyear\n\n−0.046 (0.055)\n0.038 (0.086)\n\n\nmoved × year\n\n\n−0.142 (0.112)\n\n\nNum.Obs.\n809\n534\n534\n\n\nR2 Adj.\n0.032\n0.045\n0.046\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContinuous-ish\n\n\n\n  0   1   2 \n327 277 221 \n\n\n\n\n\n\nBivariate\nMultivariate\n Interaction\n\n\n\n\n(Intercept)\n−0.150*** (0.036)\n−0.121** (0.045)\n−0.169** (0.056)\n\n\nmoved\n0.234*** (0.045)\n0.228*** (0.045)\n0.301*** (0.067)\n\n\nyear\n\n−0.029 (0.027)\n0.019 (0.042)\n\n\nmoved × year\n\n\n−0.080 (0.054)\n\n\nNum.Obs.\n809\n809\n809\n\n\nR2 Adj.\n0.032\n0.032\n0.033\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMore complex\n\n\n\n  0   1   2 \n327 277 221 \n\n\n\n\n\n\nBivariate\nMultivariate\n Interaction\n\n\n\n\n(Intercept)\n−0.150*** (0.036)\n−0.114* (0.046)\n−0.184** (0.060)\n\n\nmoved\n0.234*** (0.045)\n0.232*** (0.045)\n0.334*** (0.072)\n\n\nyear2\n\n−0.060 (0.049)\n0.077 (0.092)\n\n\nyear3\n\n−0.053 (0.054)\n0.038 (0.085)\n\n\nmoved × year2\n\n\n−0.194+ (0.109)\n\n\nmoved × year3\n\n\n−0.142 (0.110)\n\n\nNum.Obs.\n809\n809\n809\n\n\nR2 Adj.\n0.032\n0.031\n0.033"
  },
  {
    "objectID": "fp_essentials.html#differences-over-time",
    "href": "fp_essentials.html#differences-over-time",
    "title": "Workshop3",
    "section": "Differences over time",
    "text": "Differences over time\n\nCross-Sectional\n\n\n\n\n\n\nBivariate\nMultivariate\n Interaction\n\n\n\n\n(Intercept)\n−0.150*** (0.026)\n−0.148*** (0.030)\n−0.150*** (0.037)\n\n\nmoved\n0.232*** (0.032)\n0.232*** (0.032)\n0.234*** (0.046)\n\n\ntime\n\n−0.004 (0.031)\n−0.001 (0.052)\n\n\nmoved × time\n\n\n−0.004 (0.065)\n\n\nNum.Obs.\n1634\n1634\n1634\n\n\nR2 Adj.\n0.030\n0.030\n0.029\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixed Effects\n\n\n\n\n\n\nSimple\nFixed Effects\n Interaction\n\n\n\n\n(Intercept)\n0.005 (0.022)\n−0.330 (0.332)\n−0.374 (0.333)\n\n\ntime\n−0.005 (0.031)\n−0.002 (0.023)\n0.000 (0.040)\n\n\nmoved\n\n\n0.044 (0.470)\n\n\nmoved × time\n\n\n−0.004 (0.049)\n\n\nNum.Obs.\n1634\n1634\n1634\n\n\nR2 Adj.\n−0.001\n0.442\n0.442"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSCI 3200: Final Project",
    "section": "",
    "text": "Introduction\nPartisanship, or strong allegiance to one’s own political party, often colors how individuals interpret news and information, particularly in highly charged political environments. With state apparatuses being used to spread misinformation and manipulate public opinion, online echo chambers gain a new form of legitimacy as a valid news source. This study aims to delve into how an individual’s partisanship affects their trust in social media as a news source, shedding light on the dynamics that fuel the spread of misinformation through digital channels.\nAs of 2019, India had the largest number of Facebook and WhatsApp users in the world (Singh 2019). This, combined with an increasingly volatile political landscape, makes it a breeding ground for digital media-based misinformation. A 2019 Reuters study found that the levels of trust in social media were significantly higher in India than in other countries that the study focused on (which included the US, UK etc. ). In fact, while 52% of the population reported trust in Google, 54% of participants from India reported trusting in WhatsApp. (Mont’Alverne et al. 2019). This scale makes India by far the best case study to impact of social media on political polarization.\nAn Oxford Internet Institute study found that WhatsApp was a key channel for spreading disinformation by both major political parties during the 2019 national election (Campbell-Smith and Bradshaw 2019). It is estimated that, during the May 2018 Karnataka State elections alone at least 50,000 election-related WhatsApp groups were created by both the BJP and INC, the two major political parties in India. WhatsApp has emerged as the primary platform affected by disinformation in India, leading to serious societal impacts including the tragic ‘WhatsApp killings’ (The Guardian 2019).\nDespite the profound impact of WhatsApp, research exploring the influence of social group dynamics on trust and usage of WhatsApp remains scarce. A 2019 study in Chile found a significant positive correlation between the use of WhatsApp for public affairs and political knowledge (Valenzuela et al. 2019). However, it did not establish a consistent relationship between WhatsApp usage and extremity in political opinions or voting intentions. I hypothesize that in India, the dynamics may differ because political parties strategically utilize platforms like WhatsApp. Misinformation campaigns often have a communal or religious slant, targeting specific societal groups.\nIn the Indian context, research studies mostly focus on measuring the prevalence of misinformation on WhatsApp. I believe this innovates on existing studies in the field because it helps us understand the mechanism through which misinformation is disseminated, rather than its prevalance. By examining the intersection of media trust, political partisanship, and WhatsApp usage in India, this research aims to provide insights into how digital platforms, particularly WhatsApp, are exploited during elections to influence public opinion and propagate partisan beliefs. I hope this could help structure better interventions against misinformation in the future by targetting the root cause of its spread - social media users.\n\n\nHypothesis\nI hypothesize that that partisanship (how strongly individuals identify with and support a political party) impacts how much they trust the political news they encounter on WhatsApp.\nWhatsApp creates a ‘truth’ effect on its users - repeated exposure leads them to accept false information as truth due to familiarity (Kanthawala and Maddox 2022). Partisans are likely to be in social networks or groups that predominantly share news confirming their worldview, increasing their trust in such news due to repeated exposure. Badrinathan (2021), which was an experimental test of a digital literacy intervention, found that BJP supporters might be less capable of identifying misinformation post-treatment than before. They hypothesize that confirmation bias effects might be stronger in Partisans from specific parties. After being educated about misinformation, strong partisans selectively trust news from WhatsApp that reinforces their ideological positions, and only dismissing contrary information as untrustworthy because it comes from ‘foreign’ sources. This is in line with prior exposure effects in literature about misinformation (Barthwal and Jensenius 2024).\nNeyazi, Kalogeropoulos, and Nielsen (2021) explored news-seeking behaviors, trust in news, voting intentions, and concerns about misinformation among internet users. They found that partisans are more likely to engage with online news. However, they also discovered that respondents were not divided based on their party identification in their concerns about misinformation.\nWhat differentiates their participants from those in my dataset is that their participants were frequent internet users, with over 74.6% holding graduate or postgraduate degrees. This allows us to infer higher digital literacy and education levels among them, which likely explains their responses.\nIn contrast, the participants in my dataset have an average graduate/postgraduate education rate of just 37%. Hwang and Jeong (2022) found that misinformation effects were mediated by low issue knowledge, less systematic processing, and dependency on social media. Therefore, I also expect that the lower education level in my dataset will amplify the effect of party affiliation on trust in political news.\n\n\nDataset\nThe dataset at hand contains 10 different sections with data from 1309 participants surveyed on household characteristics in the state of Bihar, India. The mean age in the dataset is approximately 26.53 years (median age of 24), with the average education level of a High School diploma. The dataset is also, notably, 91.21% Male.\nThe data was sampled as part of a ‘a pedagogical, in-person treatment with educative tools to address fake news in the Indian context’ titled ‘Educative Interventions to Combat Misinformation’ by Sumitra Badrinathan, funded by the Center for the Advanced Study of India (CASI) at the University of Pennsylvania and the Judith Rodin Fellowship. The intervention consisted of 45-60 minute interviews with a survey enumerator. The data I am making use of comes from the ‘Pre-treatment Survey’ which measured pre-treatment covariates to measure intervention success. This includes demographic data such as age, education and gender and key variables such as media trust and political beliefs. (Badrinathan 2021)\nThis dataset is ideal for my research as it provides self-reported judgments regarding individuals’ ‘intensity’ of social media use on WhatsApp and their trust in WhatsApp. Additionally, it measures their ‘intensity’ of political involvement and attachment to specific political parties.\nFurthermore, it includes variables that describe pre-existing civic knowledge and digital literacy, alongside demographic information like age, gender, and education levels. This comprehensive data enables a detailed analysis of the relationship between political partisanship and trust in political news on WhatsApp, while also accounting for other important factors like digital literacy and demographics.\n\nUnderstanding the Key Variables\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nMin\nMax\nDescription\n\n\n\n\nAge\n26.53\n18\n85\nRespondent Age (Continuous)\n\n\nGender\n0.91\n0\n1\nGender (0: Female, 1: Male)\n\n\nEducation\n9.14\n1\n13\nEducation Level (1: 1st or below, 13: Post graduate and above )\n\n\nTrust in WhatsApp\n2.24\n1\n4\nTrust in WhatsApp (1: A great deal of trust, 4: Not much at all)\n\n\nPolitical Party Support\n-\n1\n7\nPolitical Party Support\n\n\nStrength of Support\n2.95\n1\n5\nStrength of Party Support (1: Extremely Strong, 4: Weak)\n\n\nImportance of WhatsApp for Political News\n-\n1\n3\nImportance of WhatsApp (1: Very Important, 3:Not Important)\n\n\nFrequency of Forwarding Political News\n2.35\n1\n7\nFrequency of Forwarding Political News (1: Several stories a day, 7: Never)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that the variables analyzed below contain ‘98’ and ‘99’ as values representing when respondents said they ‘Refused to Answer’ and ‘Don’t Know’ the answer respectively. While conducting the regression analysis - to ensure that the results were not skewed because of these outlier values - I dropped the rows that stated ‘Refused to Answer’ because there were overlapping and limited in the dataset (&lt;10 rows). For ‘Don’t Know’\nI interpreted these responses as ‘apathetic’ to the variable, since the respondents did not have strong inclinations about the question. For example, in the case of ‘Importance of WhatsApp for Political News’, I added the ‘Don’t Know’ responses to the ‘Not Important’ response.\n\n\nI wanted to visualize the existing patterns in the data for my independent and dependent variables.\nFor variables that are indicators of partisanship, I selected\n\nq37: Which political party do you support?\nq38: How strongly do you support this party?\n\n\n\n\n\n\n\n\n\n\nWe see that our data contains a higher level of support for the BJP. We also see that there are a good amount of individuals that claim “Extremely Strong” or atleast “Strong” support for their preferred party.\nTo define WhatsApp use (both direct use of WhatsApp and proxies for use of WhatsApp), I intend on using 3 main variables (in translation). I elaborate on their use in the ‘Research Design’ section.\n\nq26: How much trust and confidence do you have in the political news received on WhatsApp?\nq24_2: How important is the use of WhatsApp for news and information on politics?\nq25: How often do you forward political news that you receive on WhatsApp?\n\n\n\n\n\n\n\n\n\n\n\n\n\nResearch Design\n\nRegression\nTo test my hypothesis, I intend to start off with this standard linear regression model:\n\\[\n\\text{Trust}_{\\text{WhatsApp}} = \\beta_0 + \\beta_1 \\text{PartyAffiliation} + \\beta_2 \\text{PartySupportStrength} + \\beta_3 \\text{Education} +\n\\beta_4 \\text{Age}\n\\]\nwhere:\n\n\\(\\text{Trust}_{\\text{WhatsApp}}\\) is the dependent variable representing the level of trust in political news on WhatsApp.\n\\(\\text{PartyAffiliation}\\) is a set of dummy variables for the political party the respondent supports.\n\\(\\text{PartySupportStrength}\\) is an ordinal variable for the strength of support for the party.\n\\(\\text{Education}\\) is an ordinal variable for the highest education level of the respondent.\n\\(\\text{Age}\\) is a continuous variable representing the age of the respondent.\n\\(\\beta_0\\) is the intercept.\n\\(\\epsilon\\) is the error term.\n\nIn this specific regression analysis, a positive \\(\\epsilon\\) would support the hypothesis that individuals affiliated with certain parties (e.g., BJP supporters) have higher trust.\n\n\nAnalysing relationships\nI visualized the most primary element I am attempting to analyze Trust in WhatsApp News vs. Strength of Party Support. The results, surprisingly, strongly support my hypothesis! 86.77% of the people that have ‘Extremely Strong’ levels of party support also have a ‘Great deal of trust’ in parties.\nA heatmap was an optimal choice for this analysis because it effectively illustrates the distribution and intensity of responses across both the categorical variables I was looking at.\n\n\n\n\n\n\n\n\n\n\n\nCrafting an ‘Index’ for the Dependent Variable\nTrust in WhatsApp for political news \\(\\text{Trust}_{\\text{WhatsApp}}\\) is a complex phenomenon that cannot be fully captured by a single variable. We already know from our ‘Key Variables’ table, that while Trust in WhatsApp and Importance of Political News on WhatsApp have an average mean that indicates ‘moderate importance’, the average interviewee in this sample set still forwards politial news on Whatsapp with an average of more than one time per day.\nBy creating an index, I incorporate multiple facets of trust and usage, including the general trust in political news (q26), the importance of WhatsApp for political news (q24_2), and the frequency of forwarding political news on WhatsApp (q25). In this way, I include ‘passive’ views of WhatsApp as well as ‘active’ actions to ‘share’ information (albeit still self-reported).\nI first plotted out a correlation matrix to understand the relationships between the three variables.\n\n\n\n\n\n\n\n\n\nVariable\nTrust in Political News on WhatsApp (q26)\nImportance of WhatsApp for Political News (q24_2)\nFrequency of Forwarding Political News (q25)\n\n\n\n\nq26\n1.000000\n0.343409\n0.520145\n\n\nq24_2\n0.343409\n1.000000\n0.430391\n\n\nq25\n0.520145\n0.430391\n1.000000\n\n\n\nI found that Trust in Political News on WhatsApp is positively associated with both the frequency of forwarding political news and the perceived importance of WhatsApp for political news.\nI decided on using a z-score so each of these important variables contribute equally to the index, while enhancing the interpretability of the index. This also reduces the influence of outliers by focusing on relative positions within the distribution instead.\n\n\n\n\n\n\n\n\n\nWe can see from the plot above that the histogram is highly skewed to the right, with the majority of the z-scores clustered around 0. This indicates that most individuals in the dataset have trust levels in WhatsApp for political news that are close to the average. The average person in the dataset has moderate trust in WhatsApp, across all 3 of our selected outcome variables.\nThe right skewness suggests that while a significant portion of the population holds moderate trust, there are fewer individuals who either highly trust or distrust WhatsApp for political news. This pattern may reflect a general trend of cautious trust, where individuals are not overwhelmingly confident but still rely on WhatsApp as a significant source of political information.\n\n\nFindings\n\n\n\n\n\n\n\n\n\n\n\nIndex\nq25\nq24_2\nq26\n\n\n\n\nconst\n-0.0783\n2.5854***\n1.9334***\n1.8904***\n\n\n\n(0.1057)\n(0.2128)\n(0.0773)\n(0.1085)\n\n\nq37\n0.0080***\n0.0221***\n0.0010\n0.0069***\n\n\n\n(0.0019)\n(0.0039)\n(0.0014)\n(0.0020)\n\n\nq38\n0.0116\n0.0103\n0.0090\n0.0103\n\n\n\n(0.0080)\n(0.0160)\n(0.0058)\n(0.0082)\n\n\nq13\n0.0023\n-0.0022\n-0.0098\n0.0207**\n\n\n\n(0.0084)\n(0.0169)\n(0.0061)\n(0.0086)\n\n\nq9\n0.0006\n-0.0108**\n0.0018\n0.0043*\n\n\n\n(0.0024)\n(0.0049)\n(0.0018)\n(0.0025)\n\n\nR-squared\n0.0158\n0.0305\n0.0051\n0.0177\n\n\nR-squared Adj.\n0.0126\n0.0274\n0.0019\n0.0145\n\n\nNo. observations\n1236\n1236\n1236\n1236\n\n\n\nStandard errors in parentheses. * p&lt;.1, ** p&lt;.05, *** p&lt;.01\nThe results of the regression model test support the hypothesis that increased party affiliation is positively correlated with trust in political news on WhatsApp. The effect is small but statistically significant, indicating a modest relationship.\nFor our key independent variable of party affiliation q37, we see that the coefficient for party affiliation is 0.0080 and is statistically significant at the 1% level., This effect is relatively small, but it still indicates a modest relationship between party affiliation and the overall trust in WhatsApp for political news.\nWe can further break down the effects of q37 on our independent outcome variables.\n\nWe see that the coefficient for explicit party affiliation is 0.0221 and is statistically significant at the 1% level. This suggests that higher party affiliation is associated with a higher frequency of forwarding political news on WhatsApp. This is a small but still encouraging effect size.\nWe also see a statistically significant result for q26 which indicates that higher party affiliation is associated with increased trust in political news on WhatsApp. The effect size is small, suggesting a modest relationship.\nWe find no strong relationship between party affiliation and the perceived importance of WhatsApp for political news.\n\nIntuitively, we can interpret this as a moderate correlation. We see that political association to certain parties makes individuals more likely to forward political news on WhatsApp, and believe the news they encounter on the platform. However, they do not consciously consider WhatsApp an important source of political news.\nWe see that, unlike our visual hypothesis test with our heatmap, q38 (Strength of Party Support) is not statistically significant for any of the 4 models. We see that the coefficient for q38 is positive in all models but very small, indicating that the effect of strength of party support on the dependent variables is minimal. I guess that this effect occurs because strength of party support does not vary much among the participants. From our initial graph of the distribution of q38 it is easy to see that there’s not enough difference in responses to show a clear relationship with the dependent variables.\nIn terms of our covariates, we also find that older individuals are less likely to forward political news frequently, whereas they also trust WhatsApp as a news source more. However, we find that education is significant in the q26 model (0.0207, p&lt;0.05). The positiive (albeit small) co-efficient suggests that higher education levels are associated with moderately increased trust in political news on WhatsApp. We could be seeing this effect because of how our dataset is structured and sampled. In rural areas, those with higher education standards are associated with a higher socio-economic background, and therefore more likely to have access to digital devices such a phones. This implies the presence of other confounders that could be affecting this result. Investigating the impact of confounders on our covariates is out of the scope of this project, but suggests strongly that more information is required in this area.\n\n\nPotential Issues with the Research Design\nOne of the most significant issues with this study so far is the implication of reverse causality. In the theory we established in the ‘Introduction’ and ‘Hypothesis’ sections, we understood that polarization can affect how much echo chambers like WhatsApp appeal to you. participation in online echo chambers may exacerbate polarization, creating a feedback loop that complicates the attribution of cause and effect (Hobolt, Lawall, and Tilley 2023). This poses a considerable challenge for establishing one-directional causality.\nIn the context of an empirical study with a limited dataset, isolating this effect without structured interviews or longitudinal data is particularly challenging.\nTo help understand the effects of time, we can use q14 as a proxy variable. The variable q14, which queries respondents about how long they have had access to the internet, can serve as a proxy for early exposure to digital platforms like WhatsApp. By establishing a timeline of access, we can begin to infer the potential for earlier exposure to influence later behaviors and attitudes towards political content on WhatsApp.\nWhile q6 asks respondents about the duration of WhatsApp usage within the family over the past year, its scope is too limited to provide a comprehensive view. Through additional exploratory data analysis, I found that most respondents indicate having used WhatsApp throughout the past year. This is one of three options to indicate whether WhatsApp has been used for more than a month, more than 6 months or more than a year. This offers little variability that could produce any signficant analysis - which is why I am choosing to dive deeper mainly into the effects of q14 because it generalizes over a longer time period. This limitation underscores the need for more granular data over a longer timeline to better assess the impact of prolonged exposure to WhatsApp on political polarization.\n\n\nEmpirical Extension\nMy approach is to restrict the dataset to individuals who have had internet access for a shorter amount of time and create two subsets of our dataset - ‘long exposure’ and ‘short exposure’. I defined ‘long exposure’ as any exposure over the ‘mean’ exposure limit of the group - this was an average of 1 year on the internet. I repeated the Regression Test analysis for each subset. I present the model summaries, and a tabular analysis of difference in outcomes below.\nShort Exposure to Internet Effects\n\n\n\n\n\n\n\n\n\n\n\nIndex\nq25\nq24_2\nq26\n\n\n\n\nconst\n-0.0648\n2.5503***\n1.9393***\n1.9327***\n\n\n\n(0.122)\n(0.219)\n(0.095)\n(0.122)\n\n\nq37\n0.0099*\n0.0206**\n0.0044\n0.0074\n\n\n\n(0.005)\n(0.008)\n(0.004)\n(0.005)\n\n\nq38\n0.0098\n0.0063\n0.0088\n0.0082\n\n\n\n(0.008)\n(0.014)\n(0.006)\n(0.008)\n\n\nq13\n-0.0236*\n-0.0411*\n-0.0184*\n-0.0105\n\n\n\n(0.010)\n(0.017)\n(0.008)\n(0.010)\n\n\nq9\n0.0037\n-0.0034\n0.0024\n0.0072*\n\n\n\n(0.003)\n(0.005)\n(0.002)\n(0.003)\n\n\n\nStandard errors in parentheses. * p&lt;.1, ** p&lt;.05, *** p&lt;.01\nLong Exposure to Internet Effects\n\n\n\n\n\n\n\n\n\n\n\nIndex\nq25\nq24_2\nq26\n\n\n\n\nconst\n0.0950\n2.7002***\n2.0732***\n2.0555***\n\n\n\n(0.234)\n(0.599)\n(0.162)\n(0.243)\n\n\nq37\n0.0045*\n0.0180***\n-0.0009\n0.0030\n\n\n\n(0.002)\n(0.005)\n(0.001)\n(0.002)\n\n\nq38\n0.0541\n0.1979\n-0.0197\n0.0588\n\n\n\n(0.068)\n(0.174)\n(0.047)\n(0.070)\n\n\nq13\n0.0266\n0.0416\n-0.0038\n0.0489**\n\n\n\n(0.016)\n(0.040)\n(0.011)\n(0.016)\n\n\nq9\n-0.0059\n-0.0266*\n0.0005\n-0.0015\n\n\n\n(0.004)\n(0.011)\n(0.003)\n(0.004)\n\n\n\nStandard errors in parentheses. * p&lt;.1, ** p&lt;.05, *** p&lt;.01\nComparison of Results\nWe see that the impact of demographic and political variables on trust in WhatsApp for political content appears to be moderated by the duration of internet exposure. However, we notably see that longer exposure to internet might dilute the impact of party affiliation on WhatsApp trust. We also see that for individuals that have spent more time on the internet and have stronger party support, there is a stronger correlation with how frequently they ‘forward’ political news on WhatsApp.\nThe most interesting comparison is under the variable q13. Education consistently shows a negative trend, suggesting it might serve as a buffer reducing susceptibility to influence through platforms like WhatsApp.\nHowever, we see a similar relationship between short term and long term exposure in terms of all of our ‘key’ variables that analyze partisanship.\n\n\n\n\n\n\n\n\nVariable\nShort Exposure\nLong Exposure\n\n\n\n\nConstants\nThe constant across all dependent variables suggests baseline levels that are fairly consistent and positive.\nConstants are positive but slightly higher than in the short exposure group, indicating a higher baseline response.\n\n\nq37 (Party Affiliation)\nCoefficients are generally positive, with significant effects on the Index and q25, suggesting a positive relationship.\nEffects are more muted with significance dropping in many models except for q25, indicating that longer exposure might dilute the direct impact.\n\n\nq38 (Strength of Party Support)\nEffects are positive but mostly not significant, indicating limited direct impact on the trust metrics.\nThe coefficient in q25 is notably higher, suggesting that over time, stronger party support may be more related to specific trust aspects like q25.\n\n\nq13 (Education)\nNegative coefficients, significant in most models except q26, suggesting that higher education levels might reduce trust.\nThe direction is mixed, with some models showing negative effects, indicating variable impacts with longer internet exposure.\n\n\nq9 (Age)\nMixed effects, with only q26 showing significant positive correlation, suggesting older respondents trust WhatsApp more.\nMostly non-significant, with a negative effect on q25, indicating that age might slightly reduce the frequency of forwarding political news with more prolonged exposure.\n\n\n\n\n\nPolicy Implications of Findings\nThe results support the hypothesis that there is a positive correlation between party affiliation and trust in political news on WhatsApp, although the effect size is small. We must establish however, that these findings are indicative rather than definitive.\nThe main reason for this was that the data used in this study is observational, not experimental. We also did not eliminate entirely the potential confounder that is reverse causality. In a cross-sectional study like this, where data is collected at a single point in time, establishing temporal precedence is inherently difficult. Future research could benefit from a longitudinal design to track changes over time - testing this research design could help produce insights, for example, within a rural environment where internet access is a relatively new concept.\nWe find that the most statistically significant (though still moderate) effect on Trust in WhatsApp is Party Affiliation. Individuals associated with specific parties are more likely to spread and trust in news that have received on online resources such as WhatsApp. In the Indian context, monitoring and reprimanding political parties that engage in misinformation spread online has been met with few concrete policy solutions (Chaturvedi 2016).\nFact-checking organizations can play a critical role in verifying news stories and educating people about fake news. These organizations need to be encouraged and supported by the government and media. The ‘fact check’ unit of the Press Information Bureau (PIB) busted 1,160 cases of false information since its inception in November 2019. Government-led initiatives to integrate and promote these organizations in social media platforms, such as the formation of ‘Government monitored WhatsApp Information groups’ enable real-time checking of content as it spreads. At the same time, stronger legal frameworks that hold parties accountable when they are found to deliberately disseminate false information can prove useful, especially during election years.\nHowever, a significant challenge to these policy recommendations is the political dynamics involved, particularly with the incumbent party, the BJP, which has been frequently accused of spreading misinformation itself. This situation complicates the enforcement of such policies, as it raises concerns about impartiality and the potential misuse of regulatory mechanisms to suppress dissent or criticism.\nThe most productive contributions can come from local, grassroots organizations. FactShala, a collaborative and multi-stakeholder media literacy network pioneered by over 250 journalists and experts who run tailored workshops in over 15 languages collaborated with Google. Google’s “About This Result” feature combats misinformation by allowing users to assess information and understand its source on the internet and was translated into 8 different local Indian languages.\nOur results more clearly indicated that individuals in our dataset are ‘passive’ spreaders of misinformation. They do not believe explictly that the purpose of WhatsApp is to spread political information - but they frequently forward political news on the app and highly trust in it anyways. Policy interventions can encourage Social Media apps to add ‘digital nudges’ to alleviate ‘mindless activity’ (Purohit and Holzer 2021). We can add disclaimers before allowing individuals to forward news such as “Are you sure you want to share this article, it’s source cannot be verified.” This allows people to engage in ‘Reasoned action’ without compromising on otherwise sensitive issues with free speech and monitoring (Khan and Idris 2019).\nEffective policy measures will require a balanced approach, innovative technology solutions, and inclusive educational initiatives to foster a media-savvy citizenry capable of navigating the complexities of the information age.\n\n\n\nCode + Data\nThe Quarto files and Data can be accessed here\nThis is how I felt during most of this analysis here\n\n\nReferences\n\n\nBadrinathan, Sumitra. 2021. “Educative Interventions to Combat Misinformation: Evidence from a Field Experiment in India.” American Political Science Review 115 (4): 1325–41. https://doi.org/10.1017/S0003055421000501.\n\n\nBarthwal, Ankita, and Francesca Refsum Jensenius. 2024. “Partisanship’s Striking Resilience in India.” https://carnegieendowment.org/2024/03/22/partisanship-s-striking-resilience-in-india-pub-92025.\n\n\nCampbell-Smith, Gareth, and Samantha Bradshaw. 2019. “WhatsApp and Political Instability in India: Digital Media’s Role in the 2019 National Elections.” 2019. https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2019/05/India-Profile.pdf.\n\n\nChaturvedi, Swati. 2016. I Am a Troll: Inside the Secret World of the BJP’s Digital Army. New Delhi: Juggernaut.\n\n\nHobolt, Sara B., Katharina Lawall, and James Tilley. 2023. “The Polarizing Effect of Partisan Echo Chambers.” Cambridge University Press. https://www.cambridge.org/core/journals/journal-of-political-philosophy/article/abs/polarizing-effect-of-partisan-echo-chambers/ABCD1234.\n\n\nHwang, Yoori, and Se-Hoon Jeong. 2022. “Education-Based Gap in Misinformation Acceptance: Does the Gap Increase as Misinformation Exposure Increases?” Communication Research, 00936502221121509. https://doi.org/10.1177/00936502221121509.\n\n\nKanthawala, Shaheen, and Jessica Maddox. 2022. “Hiding in the Echo Chamber: Fact-Checking Failures and Individual Tactics of Accuracy Determination on WhatsApp in India.” Asian Journal of Communication 32 (2): 174–91. https://doi.org/10.1080/01292986.2021.2023594.\n\n\nKhan, M. Laeeq, and Ika Idris. 2019. “Recognize Misinformation and Verify Before Sharing: A Reasoned Action and Information Literacy Perspective.” Behaviour and Information Technology 38 (1): Insert Page Numbers Here. https://doi.org/10.1080/0144929X.2019.1578828.\n\n\nMont’Alverne, Camila et al. 2019. “The Trust Gap: Social Media and Elections Worldwide.” 2019. https://reutersinstitute.politics.ox.ac.uk/sites/default/files/2022-09/MontAlverne_et_al_The_Trust_Gap.pdf.\n\n\nNeyazi, Taberez Ahmed, Antonis Kalogeropoulos, and Rasmus K Nielsen. 2021. “Misinformation Concerns and Online News Participation Among Internet Users in India.” Social Media+ Society 7 (2): 1–10. https://doi.org/10.1177/20563051211009013.\n\n\nPurohit, Aditya Kumar, and Adrian Holzer. 2021. “Unhooked by Design: Scrolling Mindfully on Social Media by Automating Digital Nudges.” In Proceedings of the Twenty-Seventh Americas Conference on Information Systems. Montreal: Radboud University; Université de Neuchâtel.\n\n\nSingh, Manish. 2019. “WhatsApp Hits 400 Million Users in India, Its Biggest Market.” 2019. https://techcrunch.com/2019/07/26/whatsapp-india-users-400-million/.\n\n\nThe Guardian. 2019. “WhatsApp Murders: India Struggles to Combat Crimes Linked to Messaging Service.” 2019. https://www.theguardian.com/world/2018/jul/03/whatsapp-murders-india-struggles-to-combat-crimes-linked-to-messaging-service.\n\n\nValenzuela, Sebastián et al. 2019. “The Personal Is the Political: What Do WhatsApp Users Share and How It Matters for News Knowledge, Polarization, and Participation in Chile.” 2019. https://www.researchgate.net/publication/337426920_The_Personal_Is_the_Political_What_Do_WhatsApp_Users_Share_and_How_It_Matters_for_News_Knowledge_Polarization_and_Participation_in_Chile."
  }
]